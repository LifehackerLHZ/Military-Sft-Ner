#!/usr/bin/env python3
"""
Streamlit NER Model Comparison Demo
Side-by-side comparison of Base Qwen3-4B vs LoRA Zero3 Fine-tuned model
"""

import streamlit as st
import pandas as pd
import json
import time
import sys
import os
from pathlib import Path

# Add the demo directory to Python path
demo_dir = Path(__file__).parent
sys.path.insert(0, str(demo_dir))

from model_comparison import NERComparisonClient, ModelResult
from visualization import (
    create_inference_speed_chart,
    create_entity_type_distribution,
    create_comparison_radar_chart,
    create_entity_comparison_table
)

# Page configuration
st.set_page_config(
    page_title="SFT-ner Model Comparison Demo",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 20px;
    }
    .model-card {
        padding: 20px;
        border-radius: 10px;
        margin-bottom: 20px;
    }
    .base-model-card {
        background-color: #e3f2fd;
        border-left: 5px solid #2196f3;
    }
    .lora-model-card {
        background-color: #fce4ec;
        border-left: 5px solid #e91e63;
    }
    .entity-highlight {
        background-color: #ffff00;
        font-weight: bold;
        padding: 2px 4px;
        border-radius: 3px;
        color: #000000 !important;  /* Dark color for better contrast */
    }
    .metric-box {
        padding: 15px;
        border-radius: 8px;
        text-align: center;
        background-color: #f8f9fa;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .improvement-badge {
        background-color: #28a745;
        color: white;
        padding: 5px 10px;
        border-radius: 15px;
        font-size: 0.9em;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'client' not in st.session_state:
    import os
    base_api_url = os.getenv('BASE_API_URL', 'http://localhost:8003')
    lora_api_url = os.getenv('LORA_API_URL', 'http://localhost:8002')
    st.session_state.client = NERComparisonClient(
        base_api_url=base_api_url,
        lora_api_url=lora_api_url
    )

if 'test_results' not in st.session_state:
    st.session_state.test_results = None

if 'batch_mode' not in st.session_state:
    st.session_state.batch_mode = False

# Load test cases
@st.cache_data
def load_test_cases():
    """Load test cases from JSON file"""
    test_cases_path = demo_dir.parent / "examples" / "test_cases.json"
    if test_cases_path.exists():
        with open(test_cases_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return []

# Main header
st.markdown("<h1 class='main-header'>ğŸ¯ SFT-ner Model Comparison Demo</h1>", unsafe_allow_html=True)

st.markdown("""
<div style="text-align: center; font-size: 1.2em; color: #666; margin-bottom: 30px;">
    <span style="font-size: 0.9em;">å¯¹æ¯”åŸºåº•æ¨¡å‹ vs LoRA Zero3 Fine-tuned é€‚é…å™¨</span>
</div>
""", unsafe_allow_html=True)

# Sidebar
with st.sidebar:
    st.title("æ§åˆ¶é¢æ¿")

    st.markdown("---")

    # Mode selection
    st.subheader("ğŸ›ï¸ è¿è¡Œæ¨¡å¼")

    mode = st.radio(
        "é€‰æ‹©æ¨¡å¼",
        ["å•æ–‡æœ¬æµ‹è¯•", "æ‰¹é‡æµ‹è¯• (10ä¸ªç”¨ä¾‹)"],
        index=0
    )

    st.session_state.batch_mode = mode == "æ‰¹é‡æµ‹è¯• (10ä¸ªç”¨ä¾‹)"

    st.markdown("---")

    # Input method
    st.subheader("ğŸ“ è¾“å…¥æ–¹å¼")

    if not st.session_state.batch_mode:
        input_method = st.selectbox(
            "é€‰æ‹©è¾“å…¥æ–¹å¼",
            ["è‡ªå®šä¹‰è¾“å…¥", "æ ·ä¾‹è¾“å…¥", "é¢„è®¾æµ‹è¯•ç”¨ä¾‹"]
        )

        # Initialize session state for sample text if not exists
        if 'sample_text' not in st.session_state:
            st.session_state.sample_text = ""

        if input_method == "é¢„è®¾æµ‹è¯•ç”¨ä¾‹":
            test_cases = load_test_cases()
            if test_cases:
                case_options = [
                    f"ç”¨ä¾‹ {i+1}: {case['input'][:50]}..."
                    for i, case in enumerate(test_cases)
                ]
                selected_case = st.selectbox("é€‰æ‹©æµ‹è¯•ç”¨ä¾‹", range(len(test_cases)),
                                           format_func=lambda x: case_options[x])
                input_text = test_cases[selected_case]['input']
            else:
                st.error("æœªæ‰¾åˆ°æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶")
                input_text = ""
        elif input_method == "æ ·ä¾‹è¾“å…¥":
            import json
            import random

            # Load test samples from the JSON file
            test_file_path = "/home/ubuntu/SFT-ner/military-ner-project/data/test_processed.json"
            if os.path.exists(test_file_path):
                with open(test_file_path, 'r', encoding='utf-8') as f:
                    all_cases = json.load(f)

                # Randomly select 5-6 samples
                sample_size = min(6, len(all_cases))
                random_samples = random.sample(all_cases, sample_size)

                st.markdown("**ç‚¹å‡»ä»¥ä¸‹æ ·ä¾‹å¿«é€Ÿå¡«å……ï¼š**")

                # Create buttons for each sample
                for i, sample in enumerate(random_samples, 1):
                    sample_text_preview = sample['input'][:100] + "..." if len(sample['input']) > 100 else sample['input']

                    if st.button(f"æ ·ä¾‹ {i}: {sample_text_preview}", key=f"sample_{i}", use_container_width=True):
                        st.session_state.sample_text = sample['input']
                        st.rerun()

                # Display the text area with the selected sample
                input_text = st.text_area(
                    "è¾“å…¥å†›äº‹æ–‡æœ¬ (å·²å¡«å……æ ·ä¾‹)",
                    value=st.session_state.sample_text,
                    height=200
                )
            else:
                st.error("æœªæ‰¾åˆ°æ ·ä¾‹æ–‡ä»¶")
                input_text = ""
        else:  # è‡ªå®šä¹‰è¾“å…¥
            input_text = st.text_area(
                "è¾“å…¥å†›äº‹æ–‡æœ¬",
                height=200,
                placeholder="ä¾‹å¦‚: ç¾å›½(-39.01,-141.10)æ‹¥æœ‰448æšå‡†å¤‡å‘å°„çš„æ´²é™…å¼¹é“å¯¼å¼¹..."
            )
    else:
        st.info("æ‰¹é‡æµ‹è¯•å°†è¿è¡Œæ‰€æœ‰10ä¸ªé¢„è®¾æµ‹è¯•ç”¨ä¾‹")
        input_text = ""

    st.markdown("---")

    # Action buttons
    st.subheader("âš¡ æ“ä½œ")

    if st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary", use_container_width=True):
        st.session_state.run_analysis = True
    else:
        st.session_state.run_analysis = False

    if st.button("ğŸ”„ æ¸…ç©ºç»“æœ", use_container_width=True):
        st.session_state.test_results = None
        st.rerun()

    st.markdown("---")

    # Information
    st.subheader("â„¹ï¸ å…³äºé¡¹ç›®")

    st.info("""
    **é¡¹ç›®åç§°**: SFT-ner (Supervised Fine-Tuning for Named Entity Recognition)

    **åŸºåº•æ¨¡å‹**: Qwen3-4B (8.0Bå‚æ•°)

    **LoRAé€‚é…å™¨**: ner_zero3 (ZeRO3ä¼˜åŒ–)

    **å®ä½“ç±»å‹**:
    - ğŸ¯ å†›äº‹è£…å¤‡ (Weapon/Equipment)
    - ğŸ—ºï¸ åœ°ç†ä½ç½® (Location with Coordinates)
    - ğŸ¢ ç»„ç»‡åç§° (Organization)
    - ğŸ‘¤ äººå (Person)

    **æŠ€æœ¯**: LoRA + ZeRO3 + vLLM
    """)

# Main area
if st.session_state.batch_mode:
    st.subheader("ğŸ“Š æ‰¹é‡æµ‹è¯•æ¨¡å¼")
    st.info("æ‰¹é‡æµ‹è¯•å°†è¿è¡Œæ‰€æœ‰10ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼Œå¹¶ç”Ÿæˆè¯¦ç»†çš„æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š")

    if st.session_state.run_analysis:
        with st.spinner("æ­£åœ¨è¿è¡Œæ‰¹é‡æµ‹è¯•ï¼Œè¯·ç¨å€™..."):
            test_cases = load_test_cases()

            if not test_cases:
                st.error("æœªæ‰¾åˆ°æµ‹è¯•ç”¨ä¾‹")
            else:
                batch_results = []
                progress_bar = st.progress(0)

                for idx, case in enumerate(test_cases):
                    progress = (idx + 1) / len(test_cases)
                    progress_bar.progress(progress)

                    text = case['input']

                    with st.expander(f"æµ‹è¯•ç”¨ä¾‹ {idx + 1}", expanded=False):
                        st.markdown(f"**è¾“å…¥æ–‡æœ¬:** {text[:200]}...")

                        # Run comparison
                        base_result, lora_result = st.session_state.client.extract_entities_both(text)

                        # Calculate comparison
                        comparison = st.session_state.client.compare_entities(
                            base_result.entities, lora_result.entities
                        )

                        batch_results.append({
                            'case_id': idx + 1,
                            'text': text[:100] + "...",
                            'base_time': base_result.inference_time,
                            'lora_time': lora_result.inference_time,
                            'base_entities': base_result.entities,
                            'lora_entities': lora_result.entities,
                            'comparison': comparison
                        })

                        # Display metrics
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("Base Model", f"{len(base_result.entities)} å®ä½“")
                        with col2:
                            st.metric("LoRA Model", f"{len(lora_result.entities)} å®ä½“")
                        with col3:
                            improvement = comparison['improvement']
                            if improvement > 0:
                                st.metric("æ”¹è¿›", f"+{improvement} å®ä½“", delta_color="normal")
                            elif improvement < 0:
                                st.metric("å‡å°‘", f"{improvement} å®ä½“", delta_color="inverse")
                            else:
                                st.metric("æ— å˜åŒ–", "0")

                progress_bar.empty()

                # Store batch results
                st.session_state.batch_results = batch_results

                st.success(f"æ‰¹é‡æµ‹è¯•å®Œæˆï¼å…±æµ‹è¯• {len(test_cases)} ä¸ªç”¨ä¾‹")

                # Show summary statistics
                st.subheader("ğŸ“ˆ æ‰¹é‡æµ‹è¯•æ±‡æ€»")

                total_base_entities = sum(r['comparison']['base_total'] for r in batch_results)
                total_lora_entities = sum(r['comparison']['lora_total'] for r in batch_results)
                avg_base_time = sum(r['base_time'] for r in batch_results) / len(batch_results)
                avg_lora_time = sum(r['lora_time'] for r in batch_results) / len(batch_results)

                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("æ€»å®ä½“æ•° (Base)", total_base_entities)
                with col2:
                    st.metric("æ€»å®ä½“æ•° (LoRA)", total_lora_entities)
                with col3:
                    improvement = total_lora_entities - total_base_entities
                    st.metric("æ€»æ”¹è¿›", f"+{improvement}" if improvement > 0 else improvement)
                with col4:
                    time_diff = avg_lora_time - avg_base_time
                    st.metric("å¹³å‡æ—¶é—´å·®", f"{time_diff:.2f}s")

else:
    # Single text mode
    st.subheader("ğŸ” å•æ–‡æœ¬åˆ†ææ¨¡å¼")

    # Display input text
    if 'input_text' in locals() and input_text:
        st.markdown("#### è¾“å…¥æ–‡æœ¬")
        st.info(input_text)

    # Run analysis when button is clicked
    if st.session_state.run_analysis and 'input_text' in locals() and input_text:
        with st.spinner("æ­£åœ¨åˆ†æä¸­ï¼Œè¯·ç¨å€™..."):
            # Run both models in parallel
            base_result, lora_result = st.session_state.client.extract_entities_both(input_text)

            # Calculate comparison
            comparison = st.session_state.client.compare_entities(
                base_result.entities, lora_result.entities
            )

            st.session_state.test_results = {
                'text': input_text,
                'base': base_result,
                'lora': lora_result,
                'comparison': comparison
            }

# Display results
if st.session_state.test_results:
    results = st.session_state.test_results

    st.markdown("---")

    # Summary statistics
    st.subheader("ğŸ“Š åˆ†æç»“æœæ‘˜è¦")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.markdown("<div class='metric-box'>", unsafe_allow_html=True)
        st.markdown("<h3>Base Model</h3>", unsafe_allow_html=True)
        st.markdown(f"<p style='font-size: 2em;'>{len(results['base'].entities)}</p>", unsafe_allow_html=True)
        st.markdown(f"<p>å®ä½“æ•°<br>{results['base'].inference_time:.2f}s</p>", unsafe_allow_html=True)
        st.markdown("</div>", unsafe_allow_html=True)

    with col2:
        st.markdown("<div class='metric-box'>", unsafe_allow_html=True)
        st.markdown("<h3>LoRA Model</h3>", unsafe_allow_html=True)
        st.markdown(f"<p style='font-size: 2em;'>{len(results['lora'].entities)}</p>", unsafe_allow_html=True)
        st.markdown(f"<p>å®ä½“æ•°<br>{results['lora'].inference_time:.2f}s</p>", unsafe_allow_html=True)
        st.markdown("</div>", unsafe_allow_html=True)

    with col3:
        improvement = len(results['lora'].entities) - len(results['base'].entities)
        st.markdown("<div class='metric-box'>", unsafe_allow_html=True)
        st.markdown("<h3>æ”¹è¿›</h3>", unsafe_allow_html=True)
        color = '#28a745' if improvement >= 0 else '#dc3545'
        sign = '+' if improvement >= 0 else ''
        status = 'âœ“ æ”¹è¿›' if improvement > 0 else ('â†’ æŒå¹³' if improvement == 0 else 'â†“ å‡å°‘')
        st.markdown(f"<p style='font-size: 2em; color: {color};'>{sign}{improvement}</p>", unsafe_allow_html=True)
        st.markdown(f"<p>å®ä½“æ•°<br><span class='improvement-badge'>{status}</span></p>", unsafe_allow_html=True)
        st.markdown("</div>", unsafe_allow_html=True)

    with col4:
        time_diff = results['lora'].inference_time - results['base'].inference_time
        st.markdown("<div class='metric-box'>", unsafe_allow_html=True)
        st.markdown("<h3>æ—¶é—´å·®</h3>", unsafe_allow_html=True)
        color = '#dc3545' if time_diff > 0 else '#28a745'
        sign = '+' if time_diff > 0 else ''
        status_text = 'LoRAè¾ƒæ…¢' if time_diff > 0 else ('LoRAè¾ƒå¿«' if time_diff < 0 else 'ç›¸åŒ')
        st.markdown(f"<p style='font-size: 2em; color: {color};'>{sign}{time_diff:.2f}s</p>", unsafe_allow_html=True)
        st.markdown(f"<p>æ¨ç†æ—¶é—´<br>{status_text}</p>", unsafe_allow_html=True)
        st.markdown("</div>", unsafe_allow_html=True)

    st.markdown("---")

    # Side-by-side results
    st.subheader("ğŸ”„ å¹¶æ’ç»“æœå¯¹æ¯”")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("<div class='model-card base-model-card'>", unsafe_allow_html=True)
        st.markdown("<h3>ğŸ”µ Base Model (Qwen3-4B)</h3>", unsafe_allow_html=True)
        st.markdown(f"<p><strong>æ¨ç†æ—¶é—´ï¼š</strong> {results['base'].inference_time:.3f} ç§’</p>",
                    unsafe_allow_html=True)

        if results['base'].entities:
            st.markdown("<h4>æå–çš„å®ä½“ï¼š</h4>", unsafe_allow_html=True)
            for entity in results['base'].entities:
                entity_name = entity.get('name', 'N/A')
                entity_type = entity.get('type', 'N/A')
                html_content = f"<p>â€¢ <span class='entity-highlight'>{entity_name}</span> <span style='color: #666;'>({entity_type})</span></p>"
                st.markdown(html_content, unsafe_allow_html=True)
        else:
            st.warning("æœªæå–åˆ°å®ä½“")

        st.markdown("</div>", unsafe_allow_html=True)

    with col2:
        st.markdown("<div class='model-card lora-model-card'>", unsafe_allow_html=True)
        st.markdown("<h3>ğŸŸ£ LoRA Model (Zero3 Fine-tuned)</h3>", unsafe_allow_html=True)
        st.markdown(f"<p><strong>æ¨ç†æ—¶é—´ï¼š</strong> {results['lora'].inference_time:.3f} ç§’</p>",
                    unsafe_allow_html=True)

        if results['lora'].entities:
            st.markdown("<h4>æå–çš„å®ä½“ï¼š</h4>", unsafe_allow_html=True)
            for entity in results['lora'].entities:
                entity_name = entity.get('name', 'N/A')
                entity_type = entity.get('type', 'N/A')
                html_content = f"<p>â€¢ <span class='entity-highlight'>{entity_name}</span> <span style='color: #666;'>({entity_type})</span></p>"
                st.markdown(html_content, unsafe_allow_html=True)
        else:
            st.warning("æœªæå–åˆ°å®ä½“")

        st.markdown("</div>", unsafe_allow_html=True)

    st.markdown("---")

    # Charts section
    st.subheader("ğŸ“ˆ å¯è§†åŒ–å›¾è¡¨")

    # Create tabs for different charts
    tab1, tab2, tab3 = st.tabs(["æ¨ç†é€Ÿåº¦å¯¹æ¯”", "å®ä½“ç±»å‹åˆ†å¸ƒ", "æå–èƒ½åŠ›é›·è¾¾å›¾"])

    with tab1:
        chart_html = create_inference_speed_chart(
            {'inference_time': results['base'].inference_time},
            {'inference_time': results['lora'].inference_time}
        )
        # Wrap with plotly.js for rendering
        full_html = f"""
        <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
        <div style="height: 450px;">
            {chart_html}
        </div>
        """
        st.components.v1.html(full_html, height=450, scrolling=False)

    with tab2:
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("<h4>Base Model å®ä½“åˆ†å¸ƒ</h4>", unsafe_allow_html=True)
            chart_html = create_entity_type_distribution(results['base'].entities)
            full_html = f"""
            <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
            <div style="height: 400px;">
                {chart_html}
            </div>
            """
            st.components.v1.html(full_html, height=400, scrolling=False)
        with col2:
            st.markdown("<h4>LoRA Model å®ä½“åˆ†å¸ƒ</h4>", unsafe_allow_html=True)
            chart_html = create_entity_type_distribution(results['lora'].entities)
            full_html = f"""
            <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
            <div style="height: 400px;">
                {chart_html}
            </div>
            """
            st.components.v1.html(full_html, height=400, scrolling=False)

    with tab3:
        chart_html = create_comparison_radar_chart(
            results['base'].entities,
            results['lora'].entities
        )
        full_html = f"""
        <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
        <div style="height: 500px;">
            {chart_html}
        </div>
        """
        st.components.v1.html(full_html, height=500, scrolling=False)

    st.markdown("---")

    # Detailed comparison table
    st.subheader("ğŸ“ å®ä½“å¯¹æ¯”è¯¦æƒ…")
    comparison_table = create_entity_comparison_table(
        results['base'].entities,
        results['lora'].entities
    )
    st.components.v1.html(comparison_table, height=400, scrolling=True)

# Footer
st.markdown("---")
st.markdown("""
<div style="text-align: center; padding: 20px; color: #666;">
    <p><strong>SFT-ner Model Comparison Demo</strong></p>
    <p style="font-size: 0.9em;">Powered by Qwen3-4B + LoRA ZeRO3 Fine-tuning</p>
</div>
""", unsafe_allow_html=True)
